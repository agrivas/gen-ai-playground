{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset, load_dataset\n",
    "from huggingface_hub import notebook_login\n",
    "from peft import LoraConfig, PeftModel\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "from trl import SFTTrainer\n",
    "from IPython.display import Markdown, display # for formating Python display folowing markdown language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50fa6e9d7533455591f3a3bc83557fc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "model_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, add_eos_token=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<s> \n",
       "  [INST]\n",
       "  Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
       "  code the fibonacci series in python using reccursion\n",
       "  [/INST]\n",
       "\n",
       "  \n",
       "  </s> `def fibonacci(n):\n",
       "    if n <= 0:\n",
       "        return \"Input should be positive integer\"\n",
       "    elif n == 1:\n",
       "        return 0\n",
       "    elif n == 2:\n",
       "        return 1\n",
       "    else:\n",
       "        return fibonacci(n-1) + fibonacci(n-2)\n",
       "\n",
       "# Test the function\n",
       "print(fibonacci(10))\n",
       "`\n",
       "\n",
       "This Python code defines a recursive function called `fibonacci` that calculates the Fibonacci series. The base cases for the recursion are when the input `n` is 1 or 2, which returns 0 or 1 respectively. For other input values, the function recursively calls itself with smaller input values (`n-1` and `n-2`) and returns the sum of the results. The function also includes a check for non-positive inputs, in which case an error message is returned.</s>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_completion(query: str, model, tokenizer) -> str:\n",
    "  device = \"cuda:0\"\n",
    "\n",
    "  prompt_template = \"\"\"\n",
    "  [INST]\n",
    "  Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "  {query}\n",
    "  [/INST]\n",
    "\n",
    "  \n",
    "  \"\"\"\n",
    "  prompt = prompt_template.format(query=query)\n",
    "\n",
    "  encodeds = tokenizer(prompt, return_tensors=\"pt\", add_special_tokens=True)\n",
    "\n",
    "  model_inputs = encodeds.to(device)\n",
    "\n",
    "  generated_ids = model.generate(**model_inputs, max_new_tokens=1000, do_sample=True, pad_token_id=tokenizer.eos_token_id)\n",
    "  decoded = tokenizer.batch_decode(generated_ids)\n",
    "  return (decoded[0])\n",
    "\n",
    "result = get_completion(query=\"code the fibonacci series in python using reccursion\", model=model, tokenizer=tokenizer)\n",
    "display(Markdown(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your dataset (replace 'your_dataset_name' and 'split_name' with your actual dataset information)\n",
    "# dataset = load_dataset(\"your_dataset_name\", split=\"split_name\")\n",
    "dataset = load_dataset(\"TokenBender/code_instructions_122k_alpaca_style\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>instruction</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Below is an instruction that describes a task....</td>\n",
       "      <td>Create a function to calculate the sum of a se...</td>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td># Python code\\ndef sum_sequence(sequence):\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Below is an instruction that describes a task....</td>\n",
       "      <td>Develop a function that will add two strings</td>\n",
       "      <td>str1 = \"Hello \"\\nstr2 = \"world\"</td>\n",
       "      <td>def add_strings(str1, str2):\\n    \"\"\"This func...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Below is an instruction that describes a task....</td>\n",
       "      <td>Design a data structure in C++ to store inform...</td>\n",
       "      <td></td>\n",
       "      <td>#include &lt;map&gt;\\n#include &lt;string&gt;\\n\\nclass Gro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Below is an instruction that describes a task....</td>\n",
       "      <td>Implement a sorting algorithm to sort a given ...</td>\n",
       "      <td>[3, 1, 4, 5, 9, 0]</td>\n",
       "      <td>def bubble_sort(arr):\\n    n = len(arr)\\n \\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Below is an instruction that describes a task....</td>\n",
       "      <td>Design a Swift application for tracking expens...</td>\n",
       "      <td>Not applicable</td>\n",
       "      <td>import UIKit\\n\\nclass ExpenseViewController: U...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Below is an instruction that describes a task....</td>\n",
       "      <td>Create a REST API to convert a UNIX timestamp ...</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>&lt;?php\\n$timestamp = $_GET['timestamp'];\\n\\nif(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Below is an instruction that describes a task....</td>\n",
       "      <td>Generate a Python code for crawling a website ...</td>\n",
       "      <td>website: www.example.com \\ndata to crawl: phon...</td>\n",
       "      <td>import requests\\nimport re\\n\\ndef crawl_websit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Below is an instruction that describes a task....</td>\n",
       "      <td>Create a Python list comprehension to get the ...</td>\n",
       "      <td></td>\n",
       "      <td>[x*x for x in [1, 2, 3, 5, 8, 13]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Below is an instruction that describes a task....</td>\n",
       "      <td>Create a MySQL query to find the most expensiv...</td>\n",
       "      <td></td>\n",
       "      <td>SELECT * FROM products ORDER BY price DESC LIM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Below is an instruction that describes a task....</td>\n",
       "      <td>Create a data structure in Java for storing an...</td>\n",
       "      <td>Not applicable</td>\n",
       "      <td>public class Library {\\n \\n // map of books in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Below is an instruction that describes a task....   \n",
       "1  Below is an instruction that describes a task....   \n",
       "2  Below is an instruction that describes a task....   \n",
       "3  Below is an instruction that describes a task....   \n",
       "4  Below is an instruction that describes a task....   \n",
       "5  Below is an instruction that describes a task....   \n",
       "6  Below is an instruction that describes a task....   \n",
       "7  Below is an instruction that describes a task....   \n",
       "8  Below is an instruction that describes a task....   \n",
       "9  Below is an instruction that describes a task....   \n",
       "\n",
       "                                         instruction  \\\n",
       "0  Create a function to calculate the sum of a se...   \n",
       "1       Develop a function that will add two strings   \n",
       "2  Design a data structure in C++ to store inform...   \n",
       "3  Implement a sorting algorithm to sort a given ...   \n",
       "4  Design a Swift application for tracking expens...   \n",
       "5  Create a REST API to convert a UNIX timestamp ...   \n",
       "6  Generate a Python code for crawling a website ...   \n",
       "7  Create a Python list comprehension to get the ...   \n",
       "8  Create a MySQL query to find the most expensiv...   \n",
       "9  Create a data structure in Java for storing an...   \n",
       "\n",
       "                                               input  \\\n",
       "0                                    [1, 2, 3, 4, 5]   \n",
       "1                    str1 = \"Hello \"\\nstr2 = \"world\"   \n",
       "2                                                      \n",
       "3                                 [3, 1, 4, 5, 9, 0]   \n",
       "4                                     Not applicable   \n",
       "5                                     Not Applicable   \n",
       "6  website: www.example.com \\ndata to crawl: phon...   \n",
       "7                                                      \n",
       "8                                                      \n",
       "9                                     Not applicable   \n",
       "\n",
       "                                              output  \n",
       "0  # Python code\\ndef sum_sequence(sequence):\\n  ...  \n",
       "1  def add_strings(str1, str2):\\n    \"\"\"This func...  \n",
       "2  #include <map>\\n#include <string>\\n\\nclass Gro...  \n",
       "3  def bubble_sort(arr):\\n    n = len(arr)\\n \\n  ...  \n",
       "4  import UIKit\\n\\nclass ExpenseViewController: U...  \n",
       "5  <?php\\n$timestamp = $_GET['timestamp'];\\n\\nif(...  \n",
       "6  import requests\\nimport re\\n\\ndef crawl_websit...  \n",
       "7                 [x*x for x in [1, 2, 3, 5, 8, 13]]  \n",
       "8  SELECT * FROM products ORDER BY price DESC LIM...  \n",
       "9  public class Library {\\n \\n // map of books in...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = dataset.to_pandas()\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = load_dataset('json', data_files='../data/code-instructions/code_training_dataset.jsonl' , split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(data_point):\n",
    "    \"\"\"Gen. input text based on a prompt, task instruction, (context info.), and answer\n",
    "\n",
    "    :param data_point: dict: Data point\n",
    "    :return: dict: tokenzed prompt\n",
    "    \"\"\"\n",
    "    prefix_text = 'Below is an instruction that describes a task. Write a response that ' \\\n",
    "               'appropriately completes the request.\\n'\n",
    "    # Samples with additional context into.\n",
    "    if data_point['input']:\n",
    "        text = f\"\"\"<s>[INST]{prefix_text} {data_point[\"instruction\"]} here are the inputs {data_point[\"input\"]}[/INST]</s>\\n\\n{data_point[\"output\"]}\"\"\"\n",
    "    # Without\n",
    "    else:\n",
    "        text = f\"\"\"<s>[INST]{prefix_text} {data_point[\"instruction\"]}[/INST]</s>\\n\\n{data_point[\"output\"]}\"\"\"\n",
    "    return text\n",
    "\n",
    "# add the \"prompt\" column in the dataset\n",
    "text_column = [generate_prompt(data_point) for data_point in dataset]\n",
    "dataset = dataset.add_column(\"prompt\", text_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6134c20c148a4519993998d0a4c4b6bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/121959 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset.shuffle(seed=1234)  # Shuffle dataset here\n",
    "dataset = dataset.map(lambda samples: tokenizer(samples[\"prompt\"]), batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.train_test_split(test_size=0.2)\n",
    "train_data = dataset[\"train\"]\n",
    "test_data = dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MistralForCausalLM(\n",
      "  (model): MistralModel(\n",
      "    (embed_tokens): Embedding(32000, 4096)\n",
      "    (layers): ModuleList(\n",
      "      (0-31): 32 x MistralDecoderLayer(\n",
      "        (self_attn): MistralSdpaAttention(\n",
      "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): MistralRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): MistralMLP(\n",
      "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): MistralRMSNorm()\n",
      "        (post_attention_layernorm): MistralRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): MistralRMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, PeftModel, prepare_model_for_kbit_training, get_peft_model\n",
    "model.gradient_checkpointing_enable()\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gate_proj', 'down_proj', 'o_proj', 'k_proj', 'up_proj', 'q_proj', 'v_proj']\n"
     ]
    }
   ],
   "source": [
    "# Use the following function to find out the linear layers for fine tuning.\n",
    "# QLoRA paper : \"We find that the most critical LoRA hyperparameter is how many LoRA adapters \n",
    "# are used in total and that LoRA on all linear transformer block layers is required to match\n",
    "# full finetuning performance.\"\n",
    "\n",
    "import bitsandbytes as bnb\n",
    "\n",
    "def find_all_linear_names(model):\n",
    "  cls = bnb.nn.Linear4bit #if args.bits == 4 else (bnb.nn.Linear8bitLt if args.bits == 8 else torch.nn.Linear)\n",
    "  lora_module_names = set()\n",
    "  for name, module in model.named_modules():\n",
    "    if isinstance(module, cls):\n",
    "      names = name.split('.')\n",
    "      lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n",
    "    if 'lm_head' in lora_module_names: # needed for 16-bit\n",
    "      lora_module_names.remove('lm_head')\n",
    "  return list(lora_module_names)\n",
    "\n",
    "modules = find_all_linear_names(model)\n",
    "print(modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable: 20971520 | total: 7262703616 | Percentage: 0.2888%\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    target_modules=modules,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "trainable, total = model.get_nb_trainable_parameters()\n",
    "print(f\"Trainable: {trainable} | total: {total} | Percentage: {trainable/total*100:.4f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/gen-ai-playground/.venv/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:223: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9014e8531e0740c5bf0d3b230b270cbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/97567 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5332c19d00d246b6bfe06a1c2b72d17b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/24392 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/gen-ai-playground/.venv/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:290: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "299"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model = \"mistralai-Code-Instruct\"\n",
    "new_model_path = f\"../models/{new_model}\"\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=test_data,\n",
    "    dataset_text_field=\"prompt\",\n",
    "    peft_config=lora_config,\n",
    "    args=TrainingArguments(\n",
    "        per_device_train_batch_size=1,\n",
    "        gradient_accumulation_steps=4,\n",
    "        warmup_steps=0.03,\n",
    "        max_steps=100,\n",
    "        learning_rate=2e-4,\n",
    "        logging_steps=1,\n",
    "        output_dir=new_model_path,\n",
    "        optim=\"paged_adamw_8bit\",\n",
    "        save_strategy=\"epoch\",\n",
    "    ),\n",
    "    data_collator=DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    ")\n",
    "\n",
    "trainer.model.save_pretrained(new_model_path)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map=\"auto\")\n",
    "\n",
    "merged_model= PeftModel.from_pretrained(model, new_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<s> \n",
       "  [INST]\n",
       "  Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
       "  code the fibonacci series in python using reccursion\n",
       "  [/INST]\n",
       "\n",
       "  \n",
       "  </s> sure! Here is how you can code the Fibonacci series in Python using recursion:\n",
       "\n",
       "  ```python\n",
       "def fibonacci(n):\n",
       "    \"\"\"\n",
       "    This function returns the nth number in the Fibonacci series.\n",
       "    \"\"\"\n",
       "    if n <= 0:\n",
       "        return \"Input should be positive integer.\"\n",
       "    elif n == 1:\n",
       "        return 0\n",
       "    elif n == 2:\n",
       "        return 1\n",
       "    else:\n",
       "        return fibonacci(n-1) + fibonacci(n-2)\n",
       "\n",
       "# Testing the function\n",
       "print(fibonacci(10))\n",
       "```\n",
       "This function uses recursion to calculate the nth number in the Fibonacci series. It checks if `n` is a valid input and if so, it returns the sum of the previous two numbers in the series, which are calculated recursively. Note that recursive functions can lead to stack overflow errors if the input is too large, so this function should be used for small values of `n`.</s>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = get_completion(query=\"code the fibonacci series in python using reccursion\", model=merged_model, tokenizer=tokenizer)\n",
    "display(Markdown(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
